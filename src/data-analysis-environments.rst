.. :Authors: - Cyrus Omar, April Yi Wang 

.. title:: Data Analysis Environments

Overview
========
With the notion of extracting knowledge and insights from data, the term data science was first distinguished from pure statistics in 1997. 
University of Michigan statistics professor C.F. Jeff Wu popularized the term "data science" in his talk "Statistics = Data Science?" and he identified 3 aspects to data science which differentiate it from pure statistics :cite:`donoho:2017`: 1) data collection, 2) data modeling and analysis, 3) problem solving and decision support.

.. container:: bib-item

  .. bibliography:: data-analysis-environments.bib
    :filter: key == 'donoho:2017'

  This article reflects on the past 50 years history of data science. It introduces how the field of data science emerged as a superset of statistics and machine learning, driven by commercial rather than intellectual developments. It also visions how the field of data science will grow in next 50 years.

Data science has grown rapidly over the last decade with the rise of big data. 
It never comes to a consensus on the workflow of data science. 
Data science is often exploratory and fluid. Data scientists often take an iterative process to use the intermediate output to inform their next step for data exploration. 
Kery and Myers :cite:`kery:2017:exploring` considered data science as a practice of **exploratory programming** where programmers write code to experiment with ideas in an open-ended task.

.. container:: bib-item

  .. bibliography:: data-analysis-environments.bib
    :filter: key == 'kery:2017:exploring'

  This paper reviews and describes what exploratory programming is. It outlines four dimensions to study exploratory programming tasks: applications, required code quality, ease of difficulty of exploration, and the exploration process.  

Recently, Muller et al. :cite:`muller:2019` investigated how data science workers engaged with data.
They examined the workflow of data science by interviewing 21 data science professionals with diversed backgrounds and classifying human expertise interventions.
They described the data science practices as data acquisition, cleaning and integrating and engineering features.

.. container:: bib-item

  .. bibliography:: data-analysis-environments.bib
    :filter: key == 'muller:2019'

  This paper describes the practice of data science with a focus on how data science workers engage with data. It reports five approaches to data: data as given; as captured; as curated; as designed; and as created.

.. todo::
  Include Guo's blog post on data science workflows and challenges: https://cacm.acm.org/blogs/blog-cacm/169199-data-science-workflow-overview-and-challenges/fulltext

This chapter reflects on the challenges in the common practice of data analysis, and reports novel designs that address the challenges.
The rest of the chapter is organized as the following:
1) the first part of the article introduces novel tools and systems along the dimension if data acquisition, cleaning and integrating, and engineering features,
2) the second part of the article introduces computational notebooks, a common tool for documenting and sharing the process of data science.

Tools for Data Acquisition
==========================
Data acquisition refers to collecting data from a variety of sources.
For example, data can be downloaded as a public dataset from online repositories, or generated by physical sensors (weather data, personal health data), or collected from existing websites (flight prices, stock prices), or manually crafted (the grade of students' assignments).
In data science education, there is an increasing call to encourage students to collect and explore authentic data that are interested to themselves as to providing them a standard dataset.
The common practice for data science workers to collect data from an existing website is using web scraping tools.
However, the additional effort to learn the scraping process may block novices' interests to explore the data.


Example-Centric Live Data Analysis environments
-----------------------------------------------

**DS.js** :cite:`zhang:2017` addresses this issue by introducing the idea of example-centric live programming.
It attaches code editors to the HTML tables or datasets on an the target website.
By doing so, it embeds a lightweight data science environment directly into the data with live previews and visualizations of the computing results.
To lower the barriers of learning, DS.js further generates API suggestions to manipulate the selected data piece in the table.
In addition, DS.js encapsulates all the user generated code into a single URL for sharing.
A first-use evaluation with 8 subjects proofs the usability of the system.

.. image:: https://bearzx.github.io/DS.js/imgs/open-dsjs.gif
  :width: 800
  :alt: Loading DS.js to any HTML tables

.. container:: bib-item

  .. bibliography:: data-analysis-environments.bib
    :filter: key == 'zhang:2017'

This idea has been further explored in **Mallard** :cite:`zhang:2019`, which investigated how to turn web as a contextualized prototyping environment for machine learning.
Mallard is shown to be useful for hobbyist-level machine learning prototyping through a set of case studies, including augumenting social media sites with sentiment analysis, performing style transfer on Google Image search.

.. container:: bib-item

  .. bibliography:: data-analysis-environments.bib
    :filter: key == 'zhang:2019'

Using PBD for Web Data collection
---------------------------------

Studies have explored the possibility of using Programming by Demonstration (PBD) to facilitate the process of web data collection.

.. todo::
    Add Sarah Chasin's web automation papers

Tools for Cleaning and Integrating
==================================
Often times, data science workers receive poor-structured and incomplete dataset.
They must be cleaned or redesigned to meet the requirement of the algorithms or models.
It is said that data scientists spend most of the time collecting and cleaning the data rather than mining and modeling data.

Using PBD for Data Cleaning
---------------------------

**FlashFill** is a classical example of using programing synthesis to accerlerate the data cleaning process :cite:`gulwani:2011`.
FlashFill takes input-output examples from users, and synthesizes a program in a string expression language based on the algorithm.
The algorithm is able to produce accurate and efficient results.
It also provides noise detection, and an interactive model where users are prompted to provide outputs for ambuguis inputs.

.. raw:: html

    <div style="position: relative; height: 0; overflow: hidden; max-width: 100%; height: auto;">
    <iframe width="678" height="381" src="https://www.youtube.com/embed/ulbalvFcAYk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
    </div>

.. container:: bib-item

  .. bibliography:: data-analysis-environments.bib
    :filter: key == 'gulwani:2011'

Interactive Visual Specification
--------------------------------
.. todo::
    Wrangler - rule based

.. raw:: html

    <div style="position: relative; height: 0; overflow: hidden; max-width: 100%; height: auto;">
    <iframe title="vimeo-player" src="https://player.vimeo.com/video/19185801" width="640" height="480" frameborder="0" allowfullscreen></iframe>
    </div>

.. container:: bib-item

  .. bibliography:: data-analysis-environments.bib
    :filter: key == 'kandel:2011'

Using Crowdsourcing for Data Cleaning
-------------------------------------
.. todo::
    Introducing the problem of entity resolution + CrowdER

.. container:: bib-item

  .. bibliography:: data-analysis-environments.bib
    :filter: key == 'wang:2012'

Tools for Engineering Features
==============================

Data Visualization
------------------

.. todo::
    Vega-Lite, in situ visualization in Vega-Lite, DataInk

**Vega-Lite**

.. container:: bib-item

  .. bibliography:: data-analysis-environments2.bib
    :filter: key == 'satyanarayan:2017'

.. image:: https://idl.cs.washington.edu/static/images/figures/insitu-code-vis.png
  :width: 400
  :alt: In Situ Visualization in Vega

.. container:: bib-item

  .. bibliography:: data-analysis-environments2.bib
    :filter: key == 'hoffswell:2018'

**DataInk**

.. raw:: html

  <div style="position: relative; height: 0; overflow: hidden; max-width: 100%; height: auto;">
  <iframe width="678" height="381" src="https://www.youtube.com/embed/xlVZKGClcC0?list=TLPQMTUxMTIwMTl9VIVPBNOdFQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
  </div>

.. container:: bib-item

  .. bibliography:: data-analysis-environments2.bib
    :filter: key == 'xia:2018'

Statistical Analysis
--------------------

.. todo::
    tea-automatic statistical analysis

.. container:: bib-item

  .. bibliography:: data-analysis-environments2.bib
    :filter: key == 'jun:2019'


Machine Learning
----------------

.. container:: bib-item

  .. bibliography:: data-analysis-environments2.bib
    :filter: key == 'hohman:2019'

.. container:: bib-item

  .. bibliography:: data-analysis-environments2.bib
    :filter: key == 'wu:2019'

Computational notebooks
=======================

History of Computational Notebooks
----------------------------------

Limitations of Computational Notebooks
--------------------------------------

Managing the Masses on Notebooks
--------------------------------

Collaboration in Notebooks
--------------------------
