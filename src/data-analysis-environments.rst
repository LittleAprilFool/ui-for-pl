.. :Authors: - Cyrus Omar, April Yi Wang 

.. title:: Data Analysis Environments

Overview
========
With the notion of extracting knowledge and insights from data, the term data science was first distinguished from pure statistics in 1997. 
University of Michigan statistics professor C.F. Jeff Wu popularized the term "data science" in his talk "Statistics = Data Science?" and he identified 3 aspects to data science which differentiate it from pure statistics :cite:`donoho:2017`: 1) data collection, 2) data modeling and analysis, 3) problem solving and decision support.

.. container:: bib-item

  .. bibliography:: data-analysis-environments.bib
    :filter: key == 'donoho:2017'

  This article reflects on the past 50 years of history of data science. It introduces how the field of data science emerged as a superset of statistics and machine learning, driven by commercial rather than intellectual developments. It also visions how the field of data science will grow in the next 50 years.

Data science has grown rapidly over the last decade with the rise of big data. 
It never comes to a consensus on the workflow of data science. 
Data science is often exploratory and fluid. Data scientists often take an iterative process to use the intermediate output to inform their next step for data exploration. 
Kery and Myers :cite:`kery:2017:exploring` considered data science as a practice of **exploratory programming** where programmers write code to experiment with ideas in an open-ended task.

.. container:: bib-item

  .. bibliography:: data-analysis-environments.bib
    :filter: key == 'kery:2017:exploring'

  This paper reviews and describes what exploratory programming is. It outlines four dimensions to study exploratory programming tasks: applications, required code quality, ease of difficulty of exploration, and the exploration process.  

Recently, Muller et al. :cite:`muller:2019` investigated how data science workers engaged with data.
They examined the workflow of data science by interviewing 21 data science professionals with diverse backgrounds and classifying human expertise interventions.
They described the data science practices as data acquisition, cleaning and integrating and engineering features.

.. container:: bib-item

  .. bibliography:: data-analysis-environments.bib
    :filter: key == 'muller:2019'

  This paper describes the practice of data science with a focus on how data science workers engage with data. It reports five approaches to data: data as given; as captured; as curated; as designed; and as created.

This chapter reflects on the challenges in the common practice of data analysis, and reports novel designs that address the challenges.
The rest of the chapter is organized as the following:
1) the first part of the article introduces novel tools and systems along the dimension if data acquisition, cleaning and integrating, and engineering features,
2) the second part of the article introduces computational notebooks, a common tool for documenting and sharing the process of data science.

Tools for Data Acquisition
==========================
Data acquisition refers to collecting data from a variety of sources.
For example, data can be downloaded as a public dataset from online repositories, or generated by physical sensors (weather data, personal health data), or collected from existing websites (flight prices, stock prices), or manually crafted (the grade of students' assignments).
In data science education, there is an increasing call to encourage students to collect and explore authentic data that are meaningful to themselves rather than providing them a standard dataset.
The common practice for data science workers to collect data from an existing website is using web scraping tools.
However, the additional effort to learn the scraping process may block novices' interests to explore the data.

Using PBD for Web Data collection
---------------------------------

One approach that has been explored is using Programming by Demonstration (PBD) to facilitate the process of web data collection.
Chasin et al. first implemented Helena_, a high-level programming language for automating repetitive interactions on webpages. 
Chasin et al. then applied Programming by Demonstration (PBD) so that users only need to demonstrate how to collect data in the first row from a hierarchical website, and the system learns from the demonstration and generalizes to the other rows :cite:`chasins:2018`.

.. _Helena: http://helena-lang.org/

.. container:: bib-item

  .. bibliography:: data-analysis-environments2.bib
    :filter: key == 'chasins:2018'

Example-Centric Live Data Analysis environments
-----------------------------------------------

Another approach is to turn any webpage into a data analysis environment.
**DS.js** :cite:`zhang:2017` explored this idea by introducing the idea of example-centric live programming.
It attaches code editors to the HTML tables or datasets on the target website.
By doing so, it embeds a lightweight data science environment directly into the data with live previews and visualizations of the computing results.
To lower the barriers of learning, DS.js further generates API suggestions to manipulate the selected data piece in the table.
In addition, DS.js encapsulates all the user-generated code into a single URL for sharing.
The first-use evaluation with 8 subjects proofs the usability of the system.

.. image:: https://bearzx.github.io/DS.js/imgs/open-dsjs.gif
  :width: 800
  :alt: Loading DS.js to any HTML tables

.. container:: bib-item

  .. bibliography:: data-analysis-environments.bib
    :filter: key == 'zhang:2017'

This idea has been further explored in **Mallard** :cite:`zhang:2019`, which investigated how to turn web as a contextualized prototyping environment for machine learning.
Mallard is shown to be useful for hobbyist-level machine learning prototyping through a set of case studies, including augmenting social media sites with sentiment analysis, performing style transfer on Google Image search.

.. container:: bib-item

  .. bibliography:: data-analysis-environments.bib
    :filter: key == 'zhang:2019'

Tools for Cleaning and Integrating
==================================
Often times, data science workers receive poor-structured and incomplete datasets.
The datasets must be cleaned or redesigned to meet the requirement of the algorithms or models.
It is said that data scientists spend most of the time collecting and cleaning the data rather than mining and modeling data.
The challenge here is that there might be variants of situations that need to be considered. 
For example, a missing value may have different representations (N/A, null, '', undefined).
Data science workers may develop their own strategies to handle missing data (N/As) - deleting a record if it has too many missing attributes; using min/max/mean/median/mod to fill numerical missing attributes.
Data science workers may need to normalize numerical data, remove non-related attributes and outlier records, and encode discrete attributes to numerical values.
It is a tedious process to iterate over all possibilities.
It is also difficult to specify the transformation and reuse it across different contexts.

Interactive Visual Specification
--------------------------------
What if the system can prompt users for these transformations without asking them to write code?
Wrangler used rule-based inference to interactively suggest users valid transformations based on their current selection :cite:`kandel:2011`.
All the transformations are represented in natural language to reduce the cost of writing and reading code.
Users can specify parameters in the transformations through direct editing.
In addition, Wrangler captures the editing histories of the transformation.
In this way, data science workers can improve their efficiency comparing to manual editing.

.. raw:: html

    <div style="position: relative; height: 0; overflow: hidden; max-width: 100%; height: auto;">
    <iframe title="vimeo-player" src="https://player.vimeo.com/video/19185801" width="640" height="480" frameborder="0" allowfullscreen></iframe>
    </div>

.. container:: bib-item

  .. bibliography:: data-analysis-environments.bib
    :filter: key == 'kandel:2011'

Using PBD for Data Cleaning
---------------------------
Despite the benefits of suggesting transformations in Wrangler, data science workers are limited to preset rules.
PBD can be used for generating more intelligent suggestions.
**FlashFill** is a classical example of using programming synthesis to accelerate the data cleaning process :cite:`gulwani:2011`.
FlashFill takes input-output examples from users and synthesizes a program in a string expression language based on the algorithm.
The algorithm is able to produce accurate and efficient results.
It also provides noise detection and an interactive model where users are prompted to provide outputs for ambiguous inputs.

.. raw:: html

    <div style="position: relative; height: 0; overflow: hidden; max-width: 100%; height: auto;">
    <iframe width="678" height="381" src="https://www.youtube.com/embed/ulbalvFcAYk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
    </div>

.. container:: bib-item

  .. bibliography:: data-analysis-environments.bib
    :filter: key == 'gulwani:2011'

Using Crowdsourcing for Data Cleaning
-------------------------------------
PBD can address some of the cleaning tasks, but not all.
For example, it is hard to use an algorithmic approach to perfectly solve the problem of entity resolution.
Entity resolution refers to merging and combining different representations for the same real-world entity.
For example, a dataset may contain values for "University of Michigan", "U of M", "Umich", "UM".
They identically refer to one entity and data science workers need to replace all the ambiguous values with the same one.
It can be difficult to solve by an algorithm but can be easily judged by human knowledge.
A popular approach for these tasks is crowdsourcing - asking human workers to combine the entities.
However, this may not be scalable. 
When the size of the dataset is large, it becomes difficult for human workers to split and coordinate the work.

CrowdER addresses this with a hybrid human-machine approach :cite:`wang:2012`.
On a high level, it first uses an algorithm to filter and cluster potential values with high probabilities of duplicated entities that need crowd workers to judge.
Instead of showing crowd works pairwise comparisons, it shows cluster-based values and asks crowd workers to group these candidates.
This hybrid approach improves both efficiency and accuracy for the result.

.. container:: bib-item

  .. bibliography:: data-analysis-environments.bib
    :filter: key == 'wang:2012'

Tools for Engineering Features
==============================
Finally, the core stage of data science is engineering features, which includes understanding patterns and relations in the data, exploring different representations of the data, and finally extracting insights from the data.

Data Visualization
------------------

Data visualization can help data science workers intuitively see and explore the trends and patterns in data by creating visual representations of the information.
Vega_ is a popular declarative language for creating interactive visualizations.
Users define the interactive elements in JSON format, then Vega renders it using Canvas or SVG.
In Vega, users often need to provide a specification of the visual elements.
Vega-Lite_ is a simplified version of Vega.
Vega-Lite automates the construction of some specifications (e.g., axis, legends, scales).
Vega-Lite is compiled to Vega and can only express a subset of interactive visualizations in Vega.

 .. _Vega: https://vega.github.io/vega/
 .. _Vega-Lite: https://vega.github.io/vega-lite/

.. container:: bib-item

  .. bibliography:: data-analysis-environments2.bib
    :filter: key == 'satyanarayan:2017'

Novice users may find it difficult to draw connections with the specification and the runtime state in Vega.
Hoffswell et al. :cite:`hoffswell:2018` explored the design to visualize program variables within the code editor.
With this in situ visualization technique, novice users reported performance improvements in both speed and accuracy.

.. image:: https://idl.cs.washington.edu/static/images/figures/insitu-code-vis.png
  :width: 400
  :alt: In Situ Visualization in Vega

.. container:: bib-item

  .. bibliography:: data-analysis-environments2.bib
    :filter: key == 'hoffswell:2018'

Tools like Vega support the quick generation of visual representations, but they may require users to have expert programming skills in order to achieve the custom graphical design.
The project DearData_ creatively brings the view that people use data not only to become more efficient, but also become more humane.
It calls people to collect and hand drawing their personal data on postcards.
In this way, people have more freeform expressions of the visual elements, but they have to draw every single data points manually.
The project DataInk manages to bridge the gap between traditional visualization tools and freeform hand drawing.
It allows users to create expressive data visualizations on a digital canvas through direct pen and touch input.
It enables users to bind data attributes with visual properties (e.g., shape, color) on the design.
The research team evaluated DataInk with 8 designers and non-experts.
The results have shown that this tool encourages users to creatively generate whimsical and personal data visualizations.

.. _DearData: http://www.dear-data.com/theproject

.. raw:: html

  <div style="position: relative; height: 0; overflow: hidden; max-width: 100%; height: auto;">
  <iframe width="678" height="381" src="https://www.youtube.com/embed/xlVZKGClcC0?list=TLPQMTUxMTIwMTl9VIVPBNOdFQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
  </div>

.. container:: bib-item

  .. bibliography:: data-analysis-environments2.bib
    :filter: key == 'xia:2018'

Statistical Analysis
--------------------
Statistical analysis is the process to generate mathematically rigorous evaluations from data.
There are many statistical tests designed for different contexts and purposes, which may stand only under specific preconditions.
Thus, it is a difficult task for data science workers, especially people with little or no statistical expertise, to decide which statistical tests to use given a specific dataset and hypotheses.
Tea is a high-level declarative language to translate users' hypotheses and domain knowledge into all valid statistical tests :cite:`jun:2019`.
An initial evaluation found that Tea can help non-expert users avoid common mistakes and false conclusions. 
In addition, Tea can achieve or even beat expert recommendations on textbook tutorials.

.. container:: bib-item

  .. bibliography:: data-analysis-environments2.bib
    :filter: key == 'jun:2019'

Computational notebooks
=======================
.. todo::
  Include Guo's blog post on data science workflows and challenges: https://cacm.acm.org/blogs/blog-cacm/169199-data-science-workflow-overview-and-challenges/fulltext

One challenge - "how to consolidate all of the various notes, freehand sketches, emails, scripts, and output data files created throughout an experiment to aid in writing"

History of Computational Notebooks
----------------------------------

Limitations of Computational Notebooks
--------------------------------------

Managing the Masses on Notebooks
--------------------------------

Collaboration in Notebooks
--------------------------
